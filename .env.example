# Environment Configuration Template
# Copy this file to .env and customize for your environment

# =============================================================================
# COORDINATOR (Python FastAPI)
# =============================================================================

# PostgreSQL Database
DATABASE_URL=postgresql://troop_admin:changeme@localhost:5432/troop_ledger

# Redis Cache (for rate limiting and node registry)
REDIS_URL=redis://localhost:6379

# JWT Authentication (RSA keys)
# Generate with:
#   openssl genrsa -out coordinator_private.pem 2048
#   openssl rsa -in coordinator_private.pem -pubout -out coordinator_public.pem
JWT_PRIVATE_KEY_PATH=./coordinator_private.pem
JWT_PUBLIC_KEY_PATH=./coordinator_public.pem
JWT_EXPIRATION_SECONDS=300

# Credit System
STARTER_CREDITS=1000.0
CREDIT_MULTIPLIER=1.0

# Rate Limiting (requests per hour)
RATE_LIMIT_DEFAULT=100
RATE_LIMIT_STRICT=20

# Admin Access (for audit log endpoint)
ADMIN_PASSWORD=changeme_admin_password

# Server Configuration
HOST=0.0.0.0
PORT=8000

# =============================================================================
# WORKER (Rust)
# =============================================================================

# Tailscale IP (auto-detected if not set)
# WORKER_TAILSCALE_IP=100.x.y.z

# Coordinator URL
WORKER_COORDINATOR_URL=http://100.x.y.z:8000

# Worker Identity
WORKER_NODE_ID=worker-001

# Proxy Port (JWT verification layer)
WORKER_PROXY_PORT=8080

# Heartbeat Interval (seconds)
WORKER_HEARTBEAT_INTERVAL=30

# Model Refresh Interval (seconds) - default: 180 (3 minutes)
MODEL_REFRESH_INTERVAL=180

# Inference Engine URLs (auto-detected if not set)
OLLAMA_HOST=http://localhost:11434
VLLM_HOST=http://localhost:8000
# LM Studio always uses http://localhost:1234

# Run benchmark on startup (optional)
RUN_INITIAL_BENCHMARK=false

# =============================================================================
# CLIENT (Rust)
# =============================================================================

# Coordinator URL
CLIENT_COORDINATOR_URL=http://100.x.y.z:8000

# Local Proxy Port (OpenAI-compatible API)
CLIENT_PROXY_PORT=3000

# Client Identity (Tailscale IP or user ID)
CLIENT_REQUESTER_ID=client-001

# =============================================================================
# DEVELOPMENT
# =============================================================================

# Logging Level
RUST_LOG=info
LOG_LEVEL=INFO

# =============================================================================
# PRODUCTION
# =============================================================================

# Use strong passwords and secure key storage in production
# DATABASE_URL should use SSL: ?sslmode=require
# Store JWT keys in a secrets manager (AWS Secrets Manager, HashiCorp Vault)
# Enable audit logging to persistent storage
